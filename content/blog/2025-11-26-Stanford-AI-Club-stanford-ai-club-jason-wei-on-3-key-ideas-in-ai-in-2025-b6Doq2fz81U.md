+++
title = "Stanford AI Club: Jason Wei on 3 Key Ideas in AI in 2025"
date = 2025-11-26
draft = false

[taxonomies]
author = ["Stanford AI Club"]
categories = ["Artificial intelligence","Machine learning","Computer science--Verification","Information technology--Forecasting"]
tags = ["Adaptive compute","Verifiers law","MMLU","Benchmarking","Task verifiability","Data abundance","Alpha Evolve","Swedbench"]

[extra]
excerpt = "Jason Wei presents three foundational ideas shaping AI's trajectory in 2025: intelligence as a commoditized resource, the pivotal role of task verifiability in AI progress ('verifiers law'), and the 'jagged edge'‚Äîthe uneven, task-dependent advancement of AI capabilities. This perspective reframes how to predict which domains AI will disrupt, highlighting measurement and verification as the true bottlenecks, not just raw intelligence."
video_url = "https://www.youtube.com/watch?v=b6Doq2fz81U"
video_id = "b6Doq2fz81U"
cover = "https://img.youtube.com/vi/b6Doq2fz81U/maxresdefault.jpg"
+++

## Overview

Jason Wei presents three foundational ideas shaping AI's trajectory in 2025: intelligence as a commoditized resource, the pivotal role of task verifiability in AI progress ('verifiers law'), and the 'jagged edge'‚Äîthe uneven, task-dependent advancement of AI capabilities. This perspective reframes how to predict which domains AI will disrupt, highlighting measurement and verification as the true bottlenecks, not just raw intelligence.

## üîç Key Insights & Learnings

### Creator's Unique Angle
Wei introduces 'verifiers law,' a novel framework positing that AI's ability to master a task is directly proportional to how easily its outputs can be verified. He also emphasizes the transition from fixed to adaptive compute, arguing that this shift will continue to drive down the cost of intelligence. His 'jagged edge' model rejects the idea of uniform superintelligence, instead mapping out a nuanced, task-specific future for AI.

### The Core Problem
The central challenge addressed is predicting where and how quickly AI will achieve superhuman performance, given the uneven progress across different domains. This matters as organizations and individuals seek to future-proof skills, investments, and research focus in an era of rapid AI commoditization.

### The Solution Approach
Wei advocates a three-pronged mental model: (1) Track commoditization by monitoring cost and accessibility trends, especially as adaptive compute enables fine-grained resource allocation; (2) Apply 'verifiers law'‚Äîevaluate tasks by their verifiability to forecast AI's likely impact; (3) Use a 'jagged edge' heuristic table, scoring tasks by digital nature, human difficulty, and data abundance to predict AI disruption timelines. He supports these with concrete examples and encourages using these heuristics as predictive tools.

### Key Insights
- Intelligence is rapidly becoming a commodity, with the cost of knowledge retrieval and reasoning trending toward zero due to adaptive compute.
- Verifiability, not just solvability, is the main driver of AI progress‚Äîtasks that are easy to verify will be solved first, regardless of their inherent difficulty.
- The advancement of AI is not uniform; instead, it is highly task-dependent, leading to a 'jagged edge' where some fields are transformed rapidly while others remain largely unaffected.
- Private or insider information will become more valuable as public knowledge becomes frictionlessly accessible.
- There will not be a sudden, universal superintelligence takeoff‚Äîprogress will be piecemeal and domain-specific.

### Concepts & Definitions
- "Intelligence as a commodity": The idea that knowledge and reasoning become as cheap and accessible as electricity, driven by advances in adaptive compute.
- "Verifiers law": The principle that AI's ability to master a task is proportional to how easily its outputs can be verified, not just how hard the task is to solve.
- "Jagged edge of intelligence": The observation that AI progress is uneven across domains, with some tasks advancing quickly and others lagging due to differences in verifiability, data, and digital nature.
- Asymmetry of verification: For some tasks, it's much easier to check a solution than to generate one (e.g., Sudoku), while for others, verification is harder than generation (e.g., fact-checking essays).

### Technical Details & Implementation
- Adaptive compute: dynamically allocating computational resources at inference time based on task difficulty, as demonstrated in the 01 model for math problem solving.
- Heuristic table for task prediction: scoring tasks by digital nature, human difficulty, and data availability to estimate AI disruption timelines.
- Use of benchmarks like MMLU to track commoditization trends by measuring performance cost over time.

### Tools & Technologies
- 01 model (adaptive compute for math problems)
- MMLU benchmark (for tracking AI performance and commoditization)
- Swedbench (providing test cases to improve code verification)
- Alpha Evolve (DeepMind's work leveraging asymmetry of verification)

### Contrarian Takes & Different Approaches
- Rejects the notion of a rapid, universal superintelligence takeoff; instead, advocates for a nuanced, domain-specific view of AI progress.
- Argues that measurement and verification, not just intelligence or creativity, are the primary levers for AI advancement.
- Challenges the idea that all tasks will eventually be automated, highlighting persistent gaps in non-digital, hard-to-verify domains.

## üí° Key Takeaways & Actionable Insights

### What You Should Do
- Prioritize work and research in domains where tasks are digital, data is abundant, and verification is easy‚Äîthese will be disrupted first by AI.
- Use the verifiability heuristic to assess which tasks or job functions are most at risk of automation.
- Leverage adaptive compute strategies to optimize resource allocation for AI inference, reducing costs for easy tasks.
- Seek out or create private, non-public information assets, as their relative value will increase in a world of commoditized public knowledge.

### What to Avoid
- Do not assume uniform AI progress across all domains; avoid overgeneralizing from one field's advances to another.
- Relying solely on task difficulty for humans as a predictor of AI progress is misleading‚Äîverifiability is the true bottleneck.
- Ignoring the rising value of private information in strategic planning could lead to missed opportunities.

### Best Practices
- Apply the 'verifiers law' framework to prioritize AI research and investment.
- Track benchmark cost trends (like MMLU) to identify when intelligence for a task is becoming commoditized.
- Utilize adaptive compute to maximize efficiency and minimize costs in AI deployment.

### Personal Stories & Experiences
- Apply the 'verifiers law' framework to prioritize AI research and investment.
- Track benchmark cost trends (like MMLU) to identify when intelligence for a task is becoming commoditized.
- Utilize adaptive compute to maximize efficiency and minimize costs in AI deployment.

### Metrics & Examples
- MMLU benchmark: cost of achieving a given performance level has dropped significantly year-over-year.
- Heuristic predictions: translation (top 50 languages) already solved; basic code debugging done by 2023; AI research estimated for 2027; movie-making possibly by 2029; traditional carpet-making and personalized dating considered out of reach.

## Resources & Links

- [Video URL](https://www.youtube.com/watch?v=b6Doq2fz81U)

## Value Assessment

- **Practical Value:** conceptual framework
- **Uniqueness Factor:** cutting-edge insight
