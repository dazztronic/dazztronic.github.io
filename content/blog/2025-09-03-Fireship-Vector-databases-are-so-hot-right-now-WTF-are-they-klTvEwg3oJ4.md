+++
title = "Vector databases are so hot right now. WTF are they?"
date = 2025-09-03
draft = false

[taxonomies]
author = ["Fireship"]
categories = ["Artificial intelligence"]
tags = ["Artificial intelligence", "Databases--Vector processing", "Machine learning--Applications", "Software engineering--Open source software"]

[extra]
excerpt = "Fireship delivers a rapid-fire, irreverent breakdown of vector databases, cutting through hype with humor and hands-on code. His perspective matters because he demystifies bleeding-edge AI infrastructure, making it accessible and actionable for developers who want to build with the latest tools, not just read about them."
video_url = "https://www.youtube.com/watch?v=klTvEwg3oJ4"
video_id = "klTvEwg3oJ4"
cover = "https://img.youtube.com/vi/klTvEwg3oJ4/maxresdefault.jpg"
+++

## Overview

Fireship delivers a rapid-fire, irreverent breakdown of vector databases, cutting through hype with humor and hands-on code. His perspective matters because he demystifies bleeding-edge AI infrastructure, making it accessible and actionable for developers who want to build with the latest tools, not just read about them.

## üîç Key Insights & Learnings

### Creator's Unique Angle
Fireship's approach is to blend technical clarity with comedic skepticism, using real funding news and code demos to ground the hype in practical reality. He frames vector databases not as abstract magic, but as tangible, queryable arrays of numbers, and isn't afraid to poke fun at the gold rush mentality pervading the space.

### The Core Problem
The challenge is how to store and efficiently query high-dimensional embeddings (vectors) generated by AI models, which is critical for powering modern applications like semantic search, recommendations, and AI agents. Traditional databases aren't optimized for this, creating a bottleneck for AI-driven products.

### The Solution Approach
Fireship advocates for using purpose-built vector databases, demonstrating with a hands-on JavaScript example using Chroma and the OpenAI API. He explains the mental model: embeddings cluster semantically similar data in high-dimensional space, and vector databases enable ultra-fast similarity search. He also highlights hybrid approaches, like using PGVector with Postgres or Redis, but emphasizes the rise of native vector DBs.

### Key Insights
- The real innovation is not just storing vectors, but enabling ultra-low latency similarity search, which unlocks new AI capabilities.
- Open-source options (like Weaviate, Milvus, Chroma) are surging, but some of the most popular solutions (like Pinecone) are closed-source, raising questions about ecosystem control.
- Vector databases are becoming the backbone for emerging AGI-like tools (AutoGPT, BabyAGI), signaling a shift in how AI systems manage memory and context.

### Concepts & Definitions
- A vector is 'just an array of numbers', but embeddings map complex objects (words, images, audio) into high-dimensional space.
- Embeddings cluster semantically similar objects together, like social groups at a party, making similarity search possible.
- Vector databases are defined as systems that store and cluster arrays of numbers (embeddings) for ultra-fast similarity queries, distinct from relational or document databases.

### Technical Details & Implementation
- Uses Chroma with JavaScript, initializing a client, defining an embedding function via the OpenAI API, and storing documents with IDs and text.
- Queries are performed by passing a string (like to an LLM), and results include both the data and an array of distances (smaller = more similar).
- Mentions PGVector for Postgres and Redis vector support as hybrid solutions, but notes the performance and design advantages of native vector DBs.

### Tools & Technologies
- Chroma (open-source, ClickHouse-based)
- Weaviate (open-source, Go)
- Milvus (open-source, Go)
- Pinecone (closed-source, popular)
- PGVector (Postgres extension)
- Redis (with vector support)
- OpenAI API (for generating embeddings)
- LangChain (for chaining LLMs and vector DBs)

### Contrarian Takes & Different Approaches
- Mocks the gold rush mentality and inflated valuations in the vector DB space.
- Questions the sustainability and openness of closed-source solutions like Pinecone.
- Suggests that the real value is in practical, working code and open-source tools, not hype.

## üí° Key Takeaways & Actionable Insights

### What You Should Do
- Start experimenting with open-source vector databases like Chroma or Weaviate for new AI projects.
- Integrate vector DBs with LLMs to give your AI applications long-term memory and semantic search capabilities.
- Use the OpenAI API to generate embeddings and store them in a vector DB for immediate, practical semantic search.

### What to Avoid
- Don't assume traditional databases can handle high-dimensional vector search efficiently‚Äîpurpose-built solutions are needed.
- Beware of the hype and inflated valuations; focus on real, working code and open-source options to avoid vendor lock-in.
- Closed-source vector DBs may limit flexibility and ecosystem growth.

### Best Practices
- Use embeddings to cluster semantically similar data for smarter search and recommendations.
- Query vector DBs with natural language strings to leverage LLM-style interfaces.
- Combine vector DBs with tools like LangChain for advanced AI agent workflows.

### Personal Stories & Experiences
- Jokes about launching his own (imaginary) vector DB with a $420M valuation, lampooning the funding frenzy.
- Shares the feeling of becoming 'obsolete twice in one month' as AI tools rapidly evolve, highlighting the pace of change.
- References building a tutorial with Weaviate, signaling hands-on, ongoing learning.

### Metrics & Examples
- Weaviate: $16M Series A funding.
- Pinecone: $28M at $700M valuation.
- Chroma: $18M raised with only 1.2K GitHub stars.
- Query results include an array of distances, where a smaller number means higher similarity.

## Resources & Links

- [Video URL](https://www.youtube.com/watch?v=klTvEwg3oJ4)

## Value Assessment
- **Practical Value:** Immediately Actionable
- **Uniqueness Factor:** Fresh Perspective

