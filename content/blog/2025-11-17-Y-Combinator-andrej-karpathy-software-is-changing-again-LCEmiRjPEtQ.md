+++
title = "Andrej Karpathy: Software Is Changing (Again)"
date = 2025-11-17
draft = false

[taxonomies]
author = ["Y Combinator"]
categories = []
tags = []

[extra]
excerpt = "Andrej Karpathy reframes the evolution of software into three eras‚ÄîSoftware 1.0 (traditional code), Software 2.0 (neural network weights), and now Software 3.0 (prompting large language models in natural language). He argues that LLMs represent a fundamentally new kind of programmable computer, democratizing access to advanced computing and requiring a rethinking of infrastructure, workflows, and mental models. This matters because it signals a seismic shift in how software is built, who can build it, and the types of applications that become possible."
video_url = "https://www.youtube.com/watch?v=LCEmiRjPEtQ"
video_id = "LCEmiRjPEtQ"
cover = "https://img.youtube.com/vi/LCEmiRjPEtQ/maxresdefault.jpg"
+++

## Overview

Andrej Karpathy reframes the evolution of software into three eras‚ÄîSoftware 1.0 (traditional code), Software 2.0 (neural network weights), and now Software 3.0 (prompting large language models in natural language). He argues that LLMs represent a fundamentally new kind of programmable computer, democratizing access to advanced computing and requiring a rethinking of infrastructure, workflows, and mental models. This matters because it signals a seismic shift in how software is built, who can build it, and the types of applications that become possible.

## üîç Key Insights & Learnings

### Creator's Unique Angle
Karpathy's distinctive framework is the 'Software 1.0/2.0/3.0' taxonomy, which captures the paradigm shift from explicit programming to data-driven neural nets, and now to natural language programming with LLMs. He uniquely positions LLMs as 'people spirits'‚Äîstochastic simulations of human psychology‚Äîrequiring new collaboration models and infrastructure. His contrarian observation is that, unlike previous computing revolutions, LLMs are consumer-first, not government or enterprise-first.

### The Core Problem
The core problem addressed is how to adapt software engineering practices, infrastructure, and mental models to a world where LLMs are the primary computing substrate‚Äîprogrammable via English, fallible, and widely accessible. This is urgent because existing codebases, workflows, and security models are not designed for this new paradigm, and there is a massive need to rewrite and reimagine software.

### The Solution Approach
Karpathy advocates for meeting LLMs halfway: restructuring data and interfaces to make them LLM-friendly, leveraging tools that convert codebases into ingestible formats, and rapidly iterating on prompt-based 'programs.' He recommends thinking of LLMs as early operating systems (circa 1960s), requiring both direct programming and new infrastructure for context management, security, and collaboration. He stresses the importance of understanding LLMs' cognitive strengths and deficits, and building workflows that accommodate these.

### Key Insights
- LLMs are not just classifiers but programmable computers, with prompts as the new programming language.
- Unlike previous tech waves, LLMs are adopted by consumers first, flipping the traditional innovation diffusion model.
- LLMs have superhuman memory but lack persistent context and are prone to hallucinations‚Äîrequiring new approaches to reliability and context management.

### Concepts & Definitions
- Software 1.0: Explicit code written by humans.
- Software 2.0: Neural network weights, trained via data and optimizers.
- Software 3.0: LLMs programmed via natural language prompts.
- LLMs as 'people spirits': Stochastic simulations of human-like psychology, with both superpowers and cognitive deficits.
- Context window: The working memory of an LLM, analogous to short-term memory in humans.

### Technical Details & Implementation
- Tools like 'map of GitHub' and Hugging Face Model Atlas visualize the evolution from code to model weights.
- Changing URLs (e.g., from GitHub to get-ingest) can instantly convert repositories into LLM-ingestible text.
- Deep Wiki and tools like Devon auto-generate documentation and analyses for LLM consumption.

### Tools & Technologies
- Map of GitHub
- Hugging Face Model Atlas
- get-ingest
- Deep Wiki
- Devon

### Contrarian Takes & Different Approaches
- LLMs are not just for enterprise or government‚Äîthey are a consumer-first revolution, reversing historical patterns.
- Despite hype about autonomous agents, Karpathy is bullish on both agentic and non-agentic (LLM-assisted) workflows, advocating for a pragmatic middle ground.

## üí° Key Takeaways & Actionable Insights

### What You Should Do
- Restructure code and documentation to be easily ingestible by LLMs‚Äîuse tools that automate this process.
- Design workflows that explicitly manage LLM context windows, treating them as working memory.
- Rapidly iterate on prompts as 'programs,' leveraging LLMs' strengths and compensating for their weaknesses.

### What to Avoid
- Do not assume LLMs will gain persistent organizational knowledge over time‚Äîcontext must be managed explicitly.
- Beware of prompt injection and data leakage risks; LLMs are highly gullible and security remains immature.
- Relying on LLMs for critical logic without guardrails can lead to unpredictable, jagged intelligence failures.

### Best Practices
- Meet LLMs halfway by making data and interfaces accessible and digestible.
- Use automated tools to convert complex codebases into LLM-friendly formats.
- Treat prompt engineering as a core programming skill in the Software 3.0 era.

### Personal Stories & Experiences
- Meet LLMs halfway by making data and interfaces accessible and digestible.
- Use automated tools to convert complex codebases into LLM-friendly formats.
- Treat prompt engineering as a core programming skill in the Software 3.0 era.

### Metrics & Examples
- No specific quantitative metrics are cited, but qualitative examples include the instant, global rollout of ChatGPT to billions of users and the visualization of model weights as 'git commits' in the model space.

## Resources & Links

- [Video URL](https://www.youtube.com/watch?v=LCEmiRjPEtQ)

## Value Assessment

- **Practical Value:** immediately actionable
- **Uniqueness Factor:** cutting-edge insight
