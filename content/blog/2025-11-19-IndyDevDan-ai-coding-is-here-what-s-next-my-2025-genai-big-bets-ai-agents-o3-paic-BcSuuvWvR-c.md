+++
title = "AI Coding is here... What‚Äôs next? My 2025 GenAI BIG BETS (AI Agents, o3, Paic)"
date = 2025-11-19
draft = false

[taxonomies]
author = ["IndyDevDan"]
categories = ["Artificial intelligence","Machine learning","Software engineering--Automation","Information technology--Forecasting"]
tags = ["Generative AI","Large language models","AI agents","Personal AI assistants","Context window","Small language models","OpenAI","Anthropic","Llama","DeepSeek","Automation","Compute maximization"]

[extra]
excerpt = "IndyDevDan presents a high-conviction, action-oriented framework for staying ahead in generative AI by proactively making and betting on predictions, then building before technologies become mainstream. He emphasizes maximizing compute and leveraging AI agents and assistants as the new paradigm for productivity, with a relentless focus on actionable information and always-on automation."
video_url = "https://www.youtube.com/watch?v=BcSuuvWvR-c"
video_id = "BcSuuvWvR-c"
cover = "https://img.youtube.com/vi/BcSuuvWvR-c/maxresdefault.jpg"
+++

## Overview

IndyDevDan presents a high-conviction, action-oriented framework for staying ahead in generative AI by proactively making and betting on predictions, then building before technologies become mainstream. He emphasizes maximizing compute and leveraging AI agents and assistants as the new paradigm for productivity, with a relentless focus on actionable information and always-on automation.

## üîç Key Insights & Learnings

### Creator's Unique Angle
The approach is defined by a four-tiered mental model for technology adoption: rather than following the crowd or even the bleeding edge, Dan advocates predicting what will come next and betting on it with tangible action‚Äîbuilding systems, workflows, or businesses in anticipation of future capabilities. This 'pre-adoption' strategy is paired with a radical commitment to maxing out compute and automating knowledge work via AI agents, pushing for continuous, always-on utilization.

### The Core Problem
In a rapidly evolving AI landscape, most engineers and builders lag behind due to reactive adoption and underutilization of available capabilities (e.g., context windows, on-device models). The challenge is to gain early, actionable access to new technology and extract real value before the market saturates.

### The Solution Approach
Dan's methodology involves: (1) making annual, high-specificity predictions about AI trends; (2) turning those predictions into bets by investing time, resources, and development effort before technologies are released; (3) building infrastructure (e.g., context management systems, personal knowledge bases, AI agent wrappers) in anticipation of future model capabilities; (4) iteratively refining predictions and plans based on new information; and (5) maximizing compute by ensuring AI agents and assistants are always running, automating as much as possible.

### Key Insights
- Making and acting on predictions‚Äîrather than waiting for new tech to arrive‚Äîyields outsized returns and earliest access to opportunities.
- Most engineers underutilize current AI capabilities (e.g., context windows), missing out on competitive advantage.
- The next leap in productivity will come from always-on, agentic workflows that maximize compute and automate knowledge work.
- OpenAI will maintain its lead in LLMs through 2025, despite industry noise about competition.
- Exponential growth in AI-generated content ('slop') will force platforms to adopt stricter detection and flagging mechanisms.

### Concepts & Definitions
- "Max out your compute": Ensuring all available computational resources are continuously used by AI agents or assistants to automate and accelerate work.
- "Agentic workflow": A system where AI agents operate autonomously or semi-autonomously, handling tasks and processes without constant human intervention.
- "Prediction as a bet": Moving from speculation to action by investing time, money, or resources in anticipation of a predicted technology or trend.
- "Exponential slop": The overwhelming flood of low-value, AI-generated content that makes it difficult to find actionable information.

### Technical Details & Implementation
- Building context management systems and personal knowledge bases designed for multi-million token context windows before such models are widely available.
- Developing and deploying AI agents and personal assistants (e.g., ADA) as wrappers around prompts and models, creating layered automation.
- Utilizing on-device small language models (SLMs) at GPT-4.0 level, embedded in consumer hardware and operating systems.
- Maintaining always-on agentic workflows‚Äîensuring there is never idle compute when AI could be running tasks.

### Tools & Technologies
- OpenAI (GPT-4.0, GPT-4.0-level SLMs)
- Google (context window expansion)
- Anthropic (Claude 3.5 Sonnet)
- Meta (Llama 4)
- ADA (personal AI assistant/agent wrapper)
- DeepSeek V3

### Contrarian Takes & Different Approaches
- OpenAI's lead is underestimated and will persist, despite industry narratives about rapid competition.
- Most engineers and builders are not using even the current context window limits, let alone preparing for future expansions.
- The real productivity unlock is not more advanced models, but maximizing compute and automation with what is already available or soon to be released.

## üí° Key Takeaways & Actionable Insights

### What You Should Do
- Proactively build infrastructure (e.g., context management, knowledge bases) for anticipated model capabilities before they are released.
- Continuously monitor high-value, actionable information sources and avoid hype-driven, low-signal platforms.
- Iteratively predict, plan, and act‚Äîadjusting strategies as new information emerges.
- Remove blockers to AI adoption in your workflows; if you can automate with AI, do so immediately.
- Implement always-on agentic workflows to ensure no compute is wasted.

### What to Avoid
- Following the crowd or even just the bleeding edge results in late adoption and missed opportunities.
- Failing to act on predictions (i.e., not betting with time/resources) leads to no real advantage.
- Underutilizing available AI capabilities (like large context windows) is a missed competitive edge.
- Relying on hype or non-actionable information sources leads to wasted effort and poor decision-making.

### Best Practices
- Annual, specific prediction-making with public accountability (track win rate, e.g., 87% in 2024).
- Turning predictions into bets by building before the tech is mainstream.
- Layering AI assistants and agents to maximize automation and compute.
- Staying plugged into high-value, actionable channels (e.g., Twitter, LessWrong, Paul Graham).

### Personal Stories & Experiences
- Annual, specific prediction-making with public accountability (track win rate, e.g., 87% in 2024).
- Turning predictions into bets by building before the tech is mainstream.
- Layering AI assistants and agents to maximize automation and compute.
- Staying plugged into high-value, actionable channels (e.g., Twitter, LessWrong, Paul Graham).

### Metrics & Examples
- 2024 prediction win rate: 87% (36 out of 41 correct).
- Context windows expanding to 1-5 million tokens; personal use case recently hit 500k tokens.
- Prediction: OpenAI will top 75% of independent LLM benchmarks in 2025.

## Resources & Links

- [Video URL](https://www.youtube.com/watch?v=BcSuuvWvR-c)

## Value Assessment

- **Practical Value:** immediately actionable
- **Uniqueness Factor:** cutting-edge insight
